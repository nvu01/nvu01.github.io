<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://nvu01.github.io//feed.xml" rel="self" type="application/atom+xml" /><link href="https://nvu01.github.io//" rel="alternate" type="text/html" hreflang="en" /><updated>2025-06-09T19:46:22+00:00</updated><id>https://nvu01.github.io//feed.xml</id><title type="html">Ngan Vu</title><subtitle>Hydejack is a boutique Jekyll theme for hackers, nerds, and academics, with a focus on personal sites that are meant to impress.
</subtitle><author><name>Ngan Vu</name><email>&lt;mail@domain.tld&gt;</email></author><entry><title type="html">Undervalued Stock Scanner: From Raw Data to Smart Insights</title><link href="https://nvu01.github.io//2025-06-04-undervalued-stock-scanner/" rel="alternate" type="text/html" title="Undervalued Stock Scanner: From Raw Data to Smart Insights" /><published>2025-06-04T00:00:00+00:00</published><updated>2025-06-09T19:46:03+00:00</updated><id>https://nvu01.github.io//undervalued-stock-scanner</id><content type="html" xml:base="https://nvu01.github.io//2025-06-04-undervalued-stock-scanner/"><![CDATA[<p>Like many aspiring investors, my husband and I were drawn to the challenge of identifying undervalued stocks because they are like hidden gems with solid fundamentals that the market hasn’t caught up with yet. What started as a weekend project in Excel became a fully automated pipeline combining Power Query, VBA, and Power BI dashboards.</p>

<p><a href="https://github.com/nvu01/Undervalued-Stock-Scanner" target="_blank" rel="noopener">
  <i class="icon-github"></i> GitHub Repo
</a></p>

<p><strong>Disclaimer: This project is for educational purposes only. The analysis, models, and methods used here are not financial advice. Investing carries risk. Always do your own research or consult with a financial advisor before making investment decisions.</strong></p>

<ul class="large-only" id="markdown-toc">
  <li><a href="#project-at-a-glance" id="markdown-toc-project-at-a-glance">Project at a Glance</a></li>
  <li><a href="#datasets" id="markdown-toc-datasets">Datasets</a></li>
  <li><a href="#what-makes-a-stock-undervalued" id="markdown-toc-what-makes-a-stock-undervalued">What Makes a Stock Undervalued?</a>    <ul>
      <li><a href="#key-fundamentals" id="markdown-toc-key-fundamentals">Key Fundamentals</a></li>
      <li><a href="#how-we-evaluate-stocks-using-these-metrics" id="markdown-toc-how-we-evaluate-stocks-using-these-metrics">How We Evaluate Stocks Using These Metrics</a></li>
    </ul>
  </li>
  <li><a href="#dashboards-that-tell-a-story" id="markdown-toc-dashboards-that-tell-a-story">Dashboards that Tell a Story</a>    <ul>
      <li><a href="#dashboard-1-undervalued-stocks" id="markdown-toc-dashboard-1-undervalued-stocks">Dashboard 1: Undervalued Stocks</a>        <ul>
          <li><a href="#key-features--how-to-use-them" id="markdown-toc-key-features--how-to-use-them">Key Features &amp; How to Use Them</a></li>
        </ul>
      </li>
      <li><a href="#dashboard-2-industry-averages" id="markdown-toc-dashboard-2-industry-averages">Dashboard 2: Industry Averages</a>        <ul>
          <li><a href="#key-features--how-to-use-them-1" id="markdown-toc-key-features--how-to-use-them-1">Key Features &amp; How to Use Them</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#automating-the-mess-turning-chaos-into-clean-data" id="markdown-toc-automating-the-mess-turning-chaos-into-clean-data">Automating the Mess: Turning Chaos into Clean Data</a></li>
  <li><a href="#final-thoughts" id="markdown-toc-final-thoughts">Final Thoughts</a></li>
</ul>

<h2 id="project-at-a-glance">Project at a Glance</h2>

<p>The idea started with my husband’s interest in value investing and my curiosity for building smarter, faster workflows. He defined the investment logic and I built the engine. Our goal? Identifying potentially undervalued stocks by analyzing key financial metrics across various sectors. The project focuses on three market cap categories (Large Cap, Mid Cap, and Small Cap) and applies statistical methods to assess stock fundamentals.</p>

<h2 id="datasets">Datasets</h2>

<p>We used 11 raw CSV files exported from Thinkorswim, each representing a different sector. These contain financial fundamentals segmented by market cap:</p>

<ul>
  <li>Large-Cap: $10B+</li>
  <li>Mid-Cap: $2B–$10B</li>
  <li>Small-Cap: $250M–$2B</li>
</ul>

<p>Each sector includes multiple industries. When comparing stocks, it’s important to consider market capitalization and industry because a “good” metric in one industry or market cap can be a red flag in another. We structured the pipeline to retain this nuance throughout the analysis.</p>

<h2 id="what-makes-a-stock-undervalued">What Makes a Stock Undervalued?</h2>

<h3 id="key-fundamentals">Key Fundamentals</h3>

<p>Here’s a quick overview of the financial metrics we used:</p>

<p><strong>Price-to-Free Cash Flow ratio (P/FCF)</strong></p>

<p>Price-to-Free Cash Flow (P/FCF): A high P/FCF ratio indicates that the specific firm is trading at a high price but is not generating enough free cash flows to justify the price. Smaller price ratios are generally preferred, as they may reveal a firm generating ample cash flows that may not yet be reflected in the price.</p>

<p><strong>Price-to-Book ratio (P/B)</strong></p>

<p>Book Value Per Share (BVPS) shows a company’s net assets per share. If BVPS is higher than the stock price, the stock may be undervalued. The P/B ratio compares market price to book value. Thus, P/B of 1 means it is traded at exactly where it should be. Higher P/B means it might be overvalued.</p>

<p><strong>Return on Equity (ROE)</strong></p>

<p>This ratio is a gauge of a corporation’s profitability and how efficiently it generates those profits. The higher the ROE, the better a company is at converting its equity financing into profits.</p>

<p><strong>Return on Assets (ROA)</strong></p>

<p>Return on assets measures how effective a company’s management is in generating profit from the total assets on its balance sheet. A ROA that rises over time indicates that the company is doing well at increasing its profits with each investment dollar it spends.</p>

<p><strong>Asset-to-equity ratio (A/E)</strong></p>

<p>The asset-to-equity ratio measures a company’s financial leverage by comparing its total assets to its shareholders’ equity. A higher ratio means more debt and higher financial risk. A lower ratio signals a more conservative, equity-heavy structure.</p>

<p><strong>Price-to-Earnings ratio (P/E)</strong></p>

<p>This metric shows how much investors are paying for each dollar of earnings. A high P/E can signal high growth expectations or overvaluation. A low P/E might suggest undervaluation or strong recent performance.</p>

<h3 id="how-we-evaluate-stocks-using-these-metrics">How We Evaluate Stocks Using These Metrics</h3>
<p>Our evaluation is based on a series of carefully selected financial criteria but here’s the key: we never compare a stock to the wrong peer group. Each stock is only evaluated relative to the industry average within its own market cap category.
To make industry comparisons fair and statistically sound, we calculate the mean and standard deviation for each metric within the same industry and market cap group, <strong>excluding outliers</strong>. Outliers are identified using the interquartile range (IQR) method, and removed before calculating averages and z-scores.</p>

<p><strong>Preliminary criteria:</strong></p>

<p>To be considered “undervalued,” a stock must meet all of these:</p>
<ul>
  <li>P/FCF &gt; 0 and below the industry average</li>
  <li>P/B &gt; 0 and below the industry average</li>
  <li>A/E &gt; 1 and below the industry average</li>
  <li>ROE &gt; 10%</li>
  <li>ROA &gt; 5%</li>
</ul>

<p><strong>Additional criteria:</strong></p>

<p>We further rank stocks based on these bonus signals:</p>
<ul>
  <li>P/B &lt; 70% of industry average</li>
  <li>ROE &gt; industry average</li>
  <li>ROA &gt; industry average</li>
  <li>P/E &lt; industry average</li>
  <li>P/E between 1 and 25</li>
</ul>

<p>For each criterion met, a stock gets 1 point. The highest score a stock can get is 5 points.</p>

<h2 id="dashboards-that-tell-a-story">Dashboards that Tell a Story</h2>

<h3 id="dashboard-1-undervalued-stocks">Dashboard 1: Undervalued Stocks</h3>

<p>I created this interactive dashboard to help users explore the top-scoring undervalued stocks across sectors based on the criteria in our framework.</p>

<iframe title="Undervalued Stocks Dashboard" width="1280" height="780" src="https://app.powerbi.com/view?r=eyJrIjoiNzUyMmMxOTctMzM4Mi00YTRjLTkyNjEtNDVlNzBlZWE0NzhjIiwidCI6IjEwZGVlN2UzLWJjMGQtNGNjNy1iMzZhLWEzZDQzMGEzZGI5ZCIsImMiOjZ9&amp;pageName=6e69fbbbad14ed7e6c39" frameborder="0" allowfullscreen="true"></iframe>

<h4 id="key-features--how-to-use-them">Key Features &amp; How to Use Them</h4>

<p>This dashboard showcases stocks that meet preliminary undervaluation criteria, then scores and ranks them to help users identify top opportunities.</p>

<p><strong>1. Filter by Sector and Market Cap:</strong> You can use the filters at the right corner to select a sector (e.g., Communication Services) and market cap (Large, Mid, or Small). This tailors the view to peer groups for fair comparison.</p>

<p><strong>2. Score-Based Stock Evaluation:</strong> All stocks shown have already passed the baseline filters. Each stock is then evaluated on five additional criteria. It earns 1 point for each one met, with a maximum score of 5. The score for each stock (0-5)is shown as a horizontal stacked bar with one color-coded block per point.</p>

<p><strong>3. Z-Score Matrix:</strong> Shows how far a stock’s metric deviates from the industry average. This helps users compare each stock to its peers.</p>

<p>Undervalued metrics:</p>
<ul>
  <li>P/FCF, P/B, A/E, P/E → negative z-score is better</li>
  <li>ROE, ROA → positive z-score is better</li>
</ul>

<p>Z-scores that go in the “wrong” direction (e.g. high P/E) are grayed out.
Z-scores further from 0 (stronger deviations) are shaded in darker green, making standout values easy to spot.</p>

<p><strong>4. Summary Cards:</strong> In the dashboard, you’ll find 6 cards showing the top 3 stocks for each fundamental metric (based on z-score). These cards help users quickly identify leaders in: P/FCF, P/B, ROE, ROA, A/E, P/E</p>

<p><strong>5. Metric Breakdown Table:</strong> Scrollable table with detailed financial metrics for each stock.</p>

<p><strong>6. Tooltips for Context:</strong> Hover over the visuals to get deeper insight. Tooltips show a stock’s industry, market cap, current price and score for additional criteria.</p>

<h3 id="dashboard-2-industry-averages">Dashboard 2: Industry Averages</h3>

<p>I also created a dashboard showing industry averages of individual metrics to help users understand the financial “norms” for each industry and market cap group.</p>

<iframe title="Industry Averages Dashboard" width="1280" height="780" src="https://app.powerbi.com/view?r=eyJrIjoiZjBkYTRjNjUtYzQ2Yy00ZTNmLWFkNzMtY2Y0ZGVlMjdjNTQ0IiwidCI6IjEwZGVlN2UzLWJjMGQtNGNjNy1iMzZhLWEzZDQzMGEzZGI5ZCIsImMiOjZ9" frameborder="0" allowfullscreen="true"></iframe>

<h4 id="key-features--how-to-use-them-1">Key Features &amp; How to Use Them</h4>

<p>This dashboard provides a high-level view of how financial fundamentals vary across sectors and industries. You can use the slicers to narrow the view to the industry and market cap in you’re interested in.</p>

<p>Each visual displays industry-level averages for six core financial metrics, broken down by sector and market cap group (Large, Mid, Small):</p>
<ul>
  <li>Average P/FCF</li>
  <li>Average P/B</li>
  <li>Average ROE</li>
  <li>Average ROA</li>
  <li>Average A/E</li>
  <li>Average P/E</li>
</ul>

<p>These averages are calculated after filtering out outliers using the interquartile range method.</p>

<p>Users can use this dashboard to identify which industries are overhyped with lower profitability (ROE, ROA) but higher valuations (P/B, P/E, P/FCF).</p>

<h2 id="automating-the-mess-turning-chaos-into-clean-data">Automating the Mess: Turning Chaos into Clean Data</h2>

<p>Initially, my husband manually cleaned and analyzed the raw stock data in Excel. But with 11 sector-specific datasets and dozens of formulas, the process quickly became time-consuming, repetitive, and prone to error. Especially with frequent data updates, each refresh could take hours.</p>

<p>I completely re-engineered the process to be fast, accurate, and user-friendly by implementing a set of tools:</p>
<ul>
  <li>Power Query (20+ custom functions): For automatic cleaning and transformation.</li>
  <li>Advanced Excel formulas: For metric calculation across all datasets.</li>
  <li>VBA Macros: To refresh all data and recalculate results with a single click.</li>
  <li>Pivot tables: To calculate industry averages while filtering outliers.</li>
  <li>Dynamic file paths: So the project works across any machine without broken links.</li>
  <li>RTD function for real-time stock prices: the RTD (Real-Time Data) function integrates with the Thinkorswim platform to pull real-time stock prices directly into the workbooks.</li>
  <li>Conditional formatting: To surface strong candidates visually, making stock analysis easier for non-technical users.</li>
</ul>

<iframe title="Industry Averages Dashboard" width="1280" height="720" src="/assets/other/data_refresh_automation.gif" frameborder="0" allowfullscreen="true"></iframe>

<p>After processing the data in Excel, I brought the results into Power BI, where I created interactive dashboards that:</p>
<ul>
  <li>Compare metrics across sectors and industries</li>
  <li>Highlight top-ranking undervalued stocks</li>
  <li>Visualize trends in P/E, ROE, ROA, and other key indicators</li>
  <li>Enable non-technical users to explore insights without needing to touch the raw data</li>
</ul>

<p>All DAX measures were designed to align with the logic used in Excel, ensuring consistency between platforms.</p>

<h2 id="final-thoughts">Final Thoughts</h2>

<p>This project started with a shared curiosity and turned into a complete, repeatable workflow that saves hours and delivers clear insights. It was as much about collaboration as it was about technology. Working closely with my husband, a non-technical stakeholder, I used an informal agile approach by delivering in small chunks, gathering feedback, and adapting quickly. Clear communication and step-by-step guides I created helped my husband transition smoothly to the new process. I’m proud to have taken initiative, self-taught new skills ahead of coursework, and built a fully automated system that saves time and drives smarter investment decisions.</p>

<p>The real win? Building something that works for both analysts and non-technical users alike. It reminded me that the best data projects don’t just analyze — they simplify. They turn mess into clarity and help people make better, faster decisions. That’s what I aim to build, every time.</p>]]></content><author><name>Ngan Vu</name><email>&lt;mail@domain.tld&gt;</email></author><category term="dashboard" /><category term="stock market" /><category term="financial market" /><summary type="html"><![CDATA[A collaborative project that combines financial logic with automated Excel and Power BI tools to transform raw data into user-friendly and insight-driven dashboards.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://nvu01.github.io//assets/img/posts/2/adam-smigielski-K5mPtONmpHM-unsplash.jpg" /><media:content medium="image" url="https://nvu01.github.io//assets/img/posts/2/adam-smigielski-K5mPtONmpHM-unsplash.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Socioeconomic Factors Impacting Poverty in U.S. Counties</title><link href="https://nvu01.github.io//2025-06-01-poverty-regression-analysis/" rel="alternate" type="text/html" title="Socioeconomic Factors Impacting Poverty in U.S. Counties" /><published>2025-06-01T00:00:00+00:00</published><updated>2025-06-09T19:46:03+00:00</updated><id>https://nvu01.github.io//poverty-regression-analysis</id><content type="html" xml:base="https://nvu01.github.io//2025-06-01-poverty-regression-analysis/"><![CDATA[<p>This post summarizes my capstone project for my program in Data Analytics at WGU. I used <strong>multiple linear regression</strong> to investigate how socioeconomic factors influence poverty rates across U.S. counties.</p>

<p><a href="https://github.com/nvu01/BSDA-Capstone-Project" target="_blank" rel="noopener">
  <i class="icon-github"></i> GitHub Repo
</a></p>

<ul class="large-only" id="markdown-toc">
  <li><a href="#project-overview" id="markdown-toc-project-overview">Project Overview</a></li>
  <li><a href="#description-of-dataset" id="markdown-toc-description-of-dataset">Description of Dataset</a></li>
  <li><a href="#data-collection" id="markdown-toc-data-collection">Data Collection</a></li>
  <li><a href="#data-wrangling" id="markdown-toc-data-wrangling">Data Wrangling</a></li>
  <li><a href="#analytical-methods" id="markdown-toc-analytical-methods">Analytical Methods</a></li>
  <li><a href="#project-outcomes" id="markdown-toc-project-outcomes">Project Outcomes</a>    <ul>
      <li><a href="#models-predictive-power-and-significance" id="markdown-toc-models-predictive-power-and-significance">Model’s Predictive Power and Significance</a></li>
      <li><a href="#models-validity" id="markdown-toc-models-validity">Model’s Validity</a></li>
      <li><a href="#most-impactful-predictors" id="markdown-toc-most-impactful-predictors">Most Impactful Predictors</a>        <ul>
          <li><a href="#statistical-significance-of-individual-predictors" id="markdown-toc-statistical-significance-of-individual-predictors">Statistical Significance of Individual Predictors</a></li>
          <li><a href="#relative-importance-of-individual-predictors" id="markdown-toc-relative-importance-of-individual-predictors">Relative Importance of Individual Predictors</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#recommended-courses-of-action" id="markdown-toc-recommended-courses-of-action">Recommended Courses of Action</a></li>
  <li><a href="#final-thoughts" id="markdown-toc-final-thoughts">Final Thoughts</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>

<h2 id="project-overview">Project Overview</h2>

<p>Poverty is a multifaceted issue that is influenced by many factors such as income levels, education, employment rates, healthcare access, public programs and housing conditions. These variables interact in ways that are not immediately apparent, and their combined effects on poverty rates can vary widely across different regions. Data analysis provides objective insights rather than relying on surface-level observations. As a data analyst, I wanted to answer a critical question: <strong>What are the most important socioeconomic factors that explain poverty rates in U.S. counties, and how reliably can we model those rates using multiple linear regression?</strong></p>

<p>In this project, I applied a rigorous, statistics approach to analyze data from the U.S. Census Bureau’s 2023 American Community Survey. The goal was not just to model poverty, but to surface meaningful insights that could guide policy and resource allocation.</p>

<p>I used Jupyter Notebook as the primary development platform. The whole analytical process was done using Python libraries such as pandas for data manipulation, Matplotlib and Seaborn for visualization, NumPy for numerical operations, statsmodels for regression and statistical testing, and scikit-learn for scaling and model validation.</p>

<h2 id="description-of-dataset">Description of Dataset</h2>

<p>The dataset for this project comes from the U.S. Census Bureau’s 2023 American Community Survey (ACS) 1-Year Estimates, a trusted national source of socioeconomic data. Publicly available on <a href="https://data.census.gov/">data.census.gov</a>, the datasets include relevant indicators like income, education, unemployment, and public assistance, making it well-suited for analyzing poverty predictors at the county level.</p>

<p>A key limitation is that the poverty rate is based on the Official Poverty Measure (OPM), which doesn’t factor in regional living costs or non-cash benefits like SNAP or housing subsidies. This could limit how socioeconomic factors are interpreted. According to the Census Bureau’s 2023 <a href="https://www.census.gov/library/stories/2024/11/supplemental-poverty-measure-visualization.html" target="_blank" rel="noopener">report</a>, the OPM showed a national poverty rate of 11.5%, while the more comprehensive Supplemental Poverty Measure (SPM) reported 12.7%, underscoring the impact of additional costs and public assistance income on poverty assessments.</p>

<p>👉 <a href="https://www.census.gov/data/developers/data-sets/acs-1year.html" target="_blank" rel="noopener">More information about the U.S. Census Bureau’s ACS data</a>.</p>

<h2 id="data-collection">Data Collection</h2>

<p>The data were collected using API requests to the U.S. Census Bureau’s 2023 ACS 1-Year datasets. The data collection process required learning how ACS data is structured. The whole process felt a bit overwhelming at first because the data is structured in ways I wasn’t used to. So, I spent time going through the Census Bureau’s documentation to get a clear picture of how everything fit together, including the nuances of table formats, variable naming and the geographic codes like the ucgid.</p>

<p>Initially, I planned to manually search for variable and geographic codes, but I later developed a more efficient method. I created a Python script that searches downloaded metadata files for variable codes based on table IDs and variable labels. This tool handles case and spacing issues, reducing human error. Part of the code was adapted from this 
<a href="https://stackoverflow.com/questions/70383942/filtering-a-column-specify-case-sensitivity" target="_blank" rel="noopener">Stack Overflow thread</a>.</p>

<p>👉 <a href="/assets/html/retrieving_variable_codes.html" target="_blank" rel="noopener">See my notebook for variable code retrieval</a>.</p>

<h2 id="data-wrangling">Data Wrangling</h2>

<p>Data from ACS tables were saved as .json files, parsed using Python, and combined into a single county-level dataset with Pandas. During data preparation, I renamed coded headers to descriptive variable names, converted data types, and addressed missing or special values by imputing based on 2022 ACS data. I also removed redundant columns and combined related variables to enhance usability. The cleaned dataset was then saved as a .csv file for modeling.</p>

<p>👉 <a href="/assets/html/data_extraction_&amp;_data_wrangling.html" target="_blank" rel="noopener">See my notebook for data wrangling step</a>.</p>

<h2 id="analytical-methods">Analytical Methods</h2>

<p>I began exploratory data analysis (EDA) with <strong>descriptive statistics</strong> to examine central tendencies and spread. This is followed by calculating a <strong>correlation matrix</strong> and <strong>VIF</strong> to detect multicolinearity. Predictors with a VIF above 5 were either dropped or transformed. To explore relationships between the response and explanatory variables, I used <strong>pairplots</strong> and <strong>scatter plots</strong>. To address nonlinearity and skewness in the data, I applied appropriate transformations based on the distribution and each variable’s relationship with the response:</p>
<ul>
  <li>Log transformation for heavy right-tails</li>
  <li>Log(x+1) transformation when zeros appeared</li>
  <li>Square root transformation for moderate skew.</li>
</ul>

<p>The main analytical approach was a <strong>multiple linear regression</strong> method, which allowed me to quantify relationships between socioeconomic factors and poverty rates while considering the influence of multiple variables simultaneously. Specifically, the project used <strong>ordinary least squares (OLS)</strong> model which allowed a straightforward interpretation of coefficients, significance testing and model evaluation.</p>

<p>To evaluate the model’s predictive performance, I used metrics such as <strong>R-squared</strong> on both the training and test sets, <strong>adjusted R-squared</strong>, and <strong>mean squared error (MSE)</strong> on the test set. These metrics provided insight into how well the model fit the training data and how accurately it predicted poverty rates on new, unseen data.</p>

<p>To evaluate the role of socioeconomic factors in explaining poverty rates across U.S. counties, both a global and individual hypothesis testing framework will be used.</p>
<ul>
  <li><strong>Global hypothesis</strong> (F-test): This test evaluates whether the full set of predictors contributes to explaining poverty rates.
    <ul>
      <li>
        <p>Null hypothesis: All regression coefficients are equal to zero.<br />
  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mn>0</mn></msub><mo>:</mo><mtext>  </mtext><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><msub><mi>β</mi><mn>2</mn></msub><mo>=</mo><mo>⋯</mo><mo>=</mo><msub><mi>β</mi><mi>k</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">H_0:\;\beta_1=\beta_2=\dots=\beta_k=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span></p>
      </li>
      <li>
        <p>Alternative hypothesis: At least one regression coefficient is not equal to zero.<br />
  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mn>1</mn></msub><mo>:</mo><mtext>  </mtext><mtext>at least one </mtext><msub><mi>β</mi><mi>i</mi></msub><mo mathvariant="normal">≠</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">H_1:\;\text{at least one } \beta_i \ne 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord">at least one </span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord"><span class="mrel"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span></p>
      </li>
    </ul>
  </li>
  <li><strong>Individual hypotheses</strong> (t-test for each coefficient): These tests assess the significance of each predictor.
    <ul>
      <li>
        <p>Null Hypothesis: The coefficient for predictor i is zero.<br />
  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mn>0</mn></msub><mo>:</mo><mtext>  </mtext><msub><mi>β</mi><mi>i</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">H_0:\;\beta_i = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span></p>
      </li>
      <li>
        <p>Alternative Hypothesis: The coefficient for predictor i is not zero.<br />
  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mn>0</mn></msub><mo>:</mo><mtext>  </mtext><msub><mi>β</mi><mi>i</mi></msub><mo mathvariant="normal">≠</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">H_0:\;\beta_i \neq 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord"><span class="mrel"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span></p>
      </li>
    </ul>
  </li>
</ul>

<p>To evaluate the relative importance of each socioeconomic factor in explaining poverty rates, I also used the standardized coefficients from the multiple linear regression model. These coefficients were obtained by scaling all independent variables using <strong>MinMaxScaler</strong> before fitting the model. This will ensure that the predictors are on the same scale.</p>

<p>For the baseline model and the improved model, I implemented residual analysis to <strong>verify model assumptions</strong> and <strong>ensure the model’s validity</strong>. OLS regression relies on several assumptions: <strong>linearity</strong> of relationships between predictors and the dependent variable, <strong>homoscedasticit</strong>y (constant variance of residuals), <strong>independence of residual</strong>s, and <strong>normally distributed errors</strong>. The analysis included visualizations such as <strong>residual plots</strong>, <strong>histogram and boxplot of residual</strong>s, and <strong>Q-Q plot</strong>. This diagnostic step helped confirm whether the use of OLS and the resulting hypothesis tests were valid.</p>

<p>Finally, to address issues identified in model diagnostics, I applied several <strong>refinement methods</strong>:</p>
<ul>
  <li><strong>Square root transformation</strong> was applied to the <strong>response variable</strong> to reduce heteroscedasticity and improve linearity. The baseline model uses the raw poverty rate as the dependent variable. That may distort relationships, especially when poverty is skewed.</li>
  <li>An <strong>interaction term</strong> was added to improve model accuracy when the effect of one variable depends on another. A potential interaction term can be identified by asking this question: Do any predictors influence each other’s effects on the dependent variable? In the baseline model, I’m assuming that household income has the same effect everywhere, regardless of house values. But what if counties with medium to high income have housing affordability issues? The impact of household income on poverty may differ based on local housing cost.</li>
</ul>

<p><img src="/assets/img/posts/1/interaction_term.png" alt="description" width="550" style="display: block; margin: 0 auto;" /></p>

<p>The drop in poverty rate with increasing income appears steeper for counties with lower house value (blue cluster) than ones with higher house value (orange cluster). This means that the effect of income on poverty varies depending on house values.</p>

<p>Here’s the interaction term:<br />
<code class="language-plaintext highlighter-rouge">df2['income_x_house_value'] = (df2['log_median_income'] * df2['sqrt_median_house_value'])</code></p>

<ul>
  <li>Finally, <strong>robust standard errors (HC3)</strong> were used to produce more reliable p-values in the presence of heteroscedasticity.</li>
</ul>

<p>Once I transformed the response variable and introduced interaction, I get a clearer, more interpretable model.</p>

<p>👉 <a href="/assets/html/main_analysis.html" target="_blank" rel="noopener">See my notebook for application of analytical methods</a>.</p>

<h2 id="project-outcomes">Project Outcomes</h2>

<h3 id="models-predictive-power-and-significance">Model’s Predictive Power and Significance</h3>

<blockquote class="lead">
  <p>The refined model was statistically significant and explained over 83% of the variation in poverty on unseen data.</p>
</blockquote>

<p>My refined regression model worked well and explained 79.6% of the variance in poverty rates in training data and 83.1% in the test set. That’s high, especially for social data, where perfect predictions are rare.</p>

<p>Since the p-value is well below 0.05, we reject the null hypothesis. This indicates the model as a whole is statistically significant.</p>

<p>Final model summary:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:      sqrt_poverty_rate   R-squared:                       0.796
Model:                            OLS   Adj. R-squared:                  0.793
Method:                 Least Squares   F-statistic:                     312.2
Date:                Wed, 04 Jun 2025   Prob (F-statistic):          2.10e-219
Time:                        00:29:01   Log-Likelihood:                -139.94
No. Observations:                 674   AIC:                             297.9
Df Residuals:                     665   BIC:                             338.5
Df Model:                           8                                         
Covariance Type:                  HC3                                         

Notes:
[1] Standard Errors are heteroscedasticity robust (HC3)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R-squared (test set): 0.8310581036269753
Mean Squared Error: 0.07192225315999502
</code></pre></div></div>

<h3 id="models-validity">Model’s Validity</h3>

<blockquote class="lead">
  <p>Overall, the final model met the linear regression assumptions and its results (coefficients, p-values) can be trusted for inference.</p>
</blockquote>

<p><strong>Residual vs fitted plot:</strong> Was used to evaluate model fit and assumption validity, such as linearity and homoscedasticity.</p>

<p><img src="/assets/img/posts/1/final_residuals_fitted.png" alt="description" width="500" style="display: block; margin: 0 auto;" /></p>

<p>Residuals are randomly scattered around zero with consistent spread across fitted values. This means there is no major heteroscedasticity. A few mild outliers are present.</p>

<p><strong>Residuals vs predictors plots:</strong> Were used to detect potential non-linear relationships or predictors that could benefit from transformations.</p>

<p><img src="/assets/img/posts/1/final_residuals_predictors.png" alt="description" width="900" style="display: block; margin: 0 auto;" /></p>

<p>No strong patterns or funnel shapes. This supports the assumption of constant variance and linearity across predictors.</p>

<p><strong>Histogram and boxplot:</strong> Were used to assess whether residuals are normally distributed.</p>

<p><img src="/assets/img/posts/1/final_residuals_normality.png" alt="description" width="900" style="display: block; margin: 0 auto;" /></p>

<ul>
  <li>Histogram and boxplot of residuals: Distribution is roughly normal, bell-shaped, and symmetrical. The median is near zero, with a few mild upper-end outliers.</li>
</ul>

<p><strong>Q-Q plot:</strong> Was used to assess normality of residuals by comparing their distribution to a theoretical normal distribution.</p>

<p><img src="/assets/img/posts/1/final_qq.png" alt="description" width="500" style="display: block; margin: 0 auto;" /></p>

<ul>
  <li>Q-Q plot: Residuals closely follow the normal line with a slight deviation in the upper tail, which is acceptable.</li>
</ul>

<h3 id="most-impactful-predictors">Most Impactful Predictors</h3>

<h4 id="statistical-significance-of-individual-predictors">Statistical Significance of Individual Predictors</h4>

<blockquote class="lead">
  <p>Public assistance may still matter, despite not being statistically significant, due to how poverty is defined.</p>
</blockquote>

<p>Predictors’ metrics: <a id="predictors-metrics"></a></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>===========================================================================================
                              coef    std err          z      P&gt;|z|      [0.025      0.975]
-------------------------------------------------------------------------------------------
const                       5.0828      0.125     40.570      0.000       4.837       5.328
health_insurance           -0.3674      0.107     -3.445      0.001      -0.576      -0.158
unemployment_rate           0.8111      0.109      7.411      0.000       0.597       1.026
bachelor_holders            0.1332      0.116      1.149      0.251      -0.094       0.360
public_assistance           0.0735      0.120      0.613      0.540      -0.162       0.309
log_median_income          -5.2078      0.252    -20.651      0.000      -5.702      -4.713
log_public_transit          0.7545      0.095      7.940      0.000       0.568       0.941
sqrt_median_house_value   -18.3796      3.244     -5.666      0.000     -24.738     -12.021
income_x_house_value       20.4523      3.399      6.018      0.000      13.791      27.113
</code></pre></div></div>

<p>Based on the predictors’ p-values in the model’s summary above:</p>
<ul>
  <li><strong>Significant</strong> predictors included <strong>median income</strong>, <strong>median house value</strong>, <strong>health insurance coverage</strong>, <strong>public transit use</strong>, and an <strong>income × house value</strong> interaction.</li>
  <li>Surprisingly, <strong>public assistance rates</strong> and the <strong>percentage of bachelor’s degree holders</strong> were <strong>not statistically significant</strong> in the final model. This means that these factors have limited unique contribution to predictive power of the model once other variables were controlled.</li>
</ul>

<p>It is important to note that unlike SPM, the OPM does not include non-cash public assistance (like SNAP, housing subsidies, TANF) in its calculation. So counties with high assistance rates may not show reduced poverty under OPM even though aid might be helping in reality.</p>

<h4 id="relative-importance-of-individual-predictors">Relative Importance of Individual Predictors</h4>

<blockquote class="lead">
  <p>Counties with higher home values and incomes tend to have lower poverty rates, but each factor’s impact weakens as the other increases.</p>
</blockquote>

<p><img src="/assets/img/posts/1/tornado_diagram.png" alt="description" width="650" style="display: block; margin: 0 auto;" /></p>

<ul>
  <li>The interaction between income and house value had the largest impact. A positive coefficient for the interaction term suggests that <strong>as income increases, the negative effect of house value on poverty becomes less strong</strong>, or <strong>as house value increases, the negative effect of income on poverty rate weakens</strong>.</li>
  <li>The most impactful predictors of poverty rates are <strong>median house value</strong> and <strong>median household income</strong> as they both show strong negative relationships. <strong>Counties with higher home values and incomes tend to have lower poverty rates.</strong></li>
  <li>Other variables had smaller coefficients but still measurable effects.
    <ul>
      <li>Higher unemployment associates with higher poverty</li>
      <li>Greater health insurance coverage comes with lower poverty</li>
      <li>More public transit use relates to higher poverty (possibly reflecting urban conditions)</li>
    </ul>
  </li>
  <li>Another interesting finding is that <strong>median household income</strong> in the <strong>base model</strong> had a <strong>positive coefficient</strong> (4.7) (see the <a href="/assets/other/base_OLS Regression Results.txt" target="_blank" rel="noopener">base model summary</a>), which was unexpected because a 
<a href="/assets/img/posts/1/scatter_poverty_house-value.png" target="_blank" rel="noopener">regression plot between poverty rate and median household income</a> suggests otherwise. However, in the <strong>refined model</strong>, the sign of this coefficient flipped due to the interaction term (see <a href="#predictors-metrics">predictors’ metrics</a>). The <strong>negative coefficient</strong> means that higher housing values are associated with lower poverty rates. This adjusted effect of median house values in the final model aligns more with general economic assumptions.</li>
</ul>

<h2 id="recommended-courses-of-action">Recommended Courses of Action</h2>

<p>A local government or policymaker could use this model to identify counties most at risk based on these factors and effectively target resources or policies.</p>
<ul>
  <li>Invest in income growth and housing affordability: These were the strongest predictors of lower poverty. Policies targeting wage growth, job access, and affordable housing could significantly reduce poverty rates.</li>
  <li>Expand access to health insurance: Health insurance coverage was significantly linked to lower poverty. Improving coverage could reduce financial hardship and support poverty reduction efforts.</li>
</ul>

<h2 id="final-thoughts">Final Thoughts</h2>

<p>This project demonstrates how careful data wrangling, transparent statistical methods, and principled diagnostics can produce models that are both insightful and trustworthy. It also highlights the importance of questioning assumptions, especially when working with policy-related data.</p>

<p>Not every result was expected. Public assistance didn’t come through as a statistically significant predictor likely due to limitations of the Official Poverty Measure (OPM), which does not account for non-cash assistance like SNAP or housing vouchers. That’s a flaw in the poverty definition itself, not necessarily in the data.</p>

<p>This is a reminder: statistics model relative relationships, not realities. The real world is messier. Numbers can’t fully capture dignity, barriers, or the trade-offs that people in poverty navigate every day. Still, we can quantify strong patterns, and we should, especially when it helps guide policymakers, public agencies, and community organizations in prioritizing resources and interventions.</p>

<p>If you’re a policymaker, nonprofit leader, or fellow data scientist: I hope this analysis adds value to your work or sparks new questions worth pursuing.</p>

<h2 id="references">References</h2>
<ul>
  <li>Creamer, J., &amp; King, M. D. (2024, November 14). <a href="https://www.census.gov/library/stories/2024/11/supplemental-poverty-measure-visualization.html">How Do Policies and Expenses Affect Supplemental Poverty Rates?</a></li>
</ul>]]></content><author><name>Ngan Vu</name><email>&lt;mail@domain.tld&gt;</email></author><category term="regression" /><category term="socioeconomic data" /><category term="poverty" /><category term="census data" /><category term="public policy" /><summary type="html"><![CDATA[A regression-based analysis of how socioeconomic variables drive poverty rates across U.S. counties, using data from the U.S. Census Bureau.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://nvu01.github.io//assets/img/posts/1/kostiantyn-li-1sCXwVoqKAw-unsplash.jpg" /><media:content medium="image" url="https://nvu01.github.io//assets/img/posts/1/kostiantyn-li-1sCXwVoqKAw-unsplash.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">U.S. YouTube Video Trends: A Tableau Dashboard &amp;amp; Story</title><link href="https://nvu01.github.io//2025-05-28-youtube-video-trends/" rel="alternate" type="text/html" title="U.S. YouTube Video Trends: A Tableau Dashboard &amp;amp; Story" /><published>2025-05-28T00:00:00+00:00</published><updated>2025-06-09T19:46:03+00:00</updated><id>https://nvu01.github.io//youtube-video-trends</id><content type="html" xml:base="https://nvu01.github.io//2025-05-28-youtube-video-trends/"><![CDATA[<p>What do trending YouTube videos reveal about American viewers? In this Tableau project, I analyzed U.S. YouTube trending data to uncover patterns in viewer sentiment, identify top-performing creators, and explore regional content preferences.</p>

<p><a href="https://github.com/nvu01/Tableau-Public-Dashboard/tree/main" target="_blank" rel="noopener">
  <i class="icon-github"></i> GitHub Repo
</a></p>

<ul class="large-only" id="markdown-toc">
  <li><a href="#data-source" id="markdown-toc-data-source">Data Source</a></li>
  <li><a href="#what-i-set-out-to-discover" id="markdown-toc-what-i-set-out-to-discover">What I Set Out to Discover</a></li>
  <li><a href="#interactive-dashboard" id="markdown-toc-interactive-dashboard">Interactive Dashboard</a></li>
  <li><a href="#guided-story-a-walkthrough-of-insights" id="markdown-toc-guided-story-a-walkthrough-of-insights">Guided Story: A Walkthrough of Insights</a></li>
  <li><a href="#key-takeaways" id="markdown-toc-key-takeaways">Key Takeaways</a></li>
  <li><a href="#behind-the-visualizations" id="markdown-toc-behind-the-visualizations">Behind the Visualizations</a></li>
  <li><a href="#final-thoughts" id="markdown-toc-final-thoughts">Final Thoughts</a></li>
</ul>

<h2 id="data-source">Data Source</h2>

<p>For my data visualization project, I am using datasets containing statistics on trending YouTube videos in the U.S. These datasets were originally sourced from Kaggle and then transformed and cleaned by Udacity for educational purposes. The cleaned datasets can be found in my <a href="https://github.com/nvu01/Tableau-Public-Dashboard/tree/main">GitHub repo</a>.</p>

<p>Data source: <a href="https://www.kaggle.com/datasets/datasnaek/youtube-new/data?select=USvideos.csv">Kaggle</a></p>

<h2 id="what-i-set-out-to-discover">What I Set Out to Discover</h2>

<p>I designed four interactive visualizations to tell a story and answer deeper questions that go beyond surface metrics like views or likes. These business questions guided the structure and design of the dashboard:</p>
<ul>
  <li>Do more popular videos also attract more criticism?</li>
  <li>Which creators consistently break through the noise?</li>
  <li>Are some categories winning because of volume, or higher per-video impact?</li>
  <li>How does content preference vary across the U.S.?</li>
</ul>

<h2 id="interactive-dashboard">Interactive Dashboard</h2>

<p>Let’s explore the full dashboard here! Filter by category, hover over the charts for tooltips, and uncover deeper insights as you interact with the data.</p>

<iframe src="https://public.tableau.com/views/U_S_YouTubeVideoTrends/U_S_YouTubeVideoTrends?:showVizHome=no&amp;:embed=true" width="1280" height="725" frameborder="0" allowfullscreen="">
</iframe>

<h2 id="guided-story-a-walkthrough-of-insights">Guided Story: A Walkthrough of Insights</h2>

<p>This Tableau Story walks you through the key findings, one insight at a time.</p>

<iframe src="https://public.tableau.com/views/StoryU_S_YouTubeVideoTrends/Story?:showVizHome=no&amp;:embed=true" width="1000" height="827px" frameborder="0" allowfullscreen="">
</iframe>

<h2 id="key-takeaways">Key Takeaways</h2>

<ul>
  <li><strong>Popularity attracts polarity.</strong> Trending videos with high likes often come with a high number of dislikes.</li>
  <li><strong>Big brands dominate.</strong> Marvel Entertainment and YouTube Spotlight top the charts in total views.</li>
  <li><strong>Music wins in impact.</strong> Fewer videos, but each with massive reach.</li>
  <li><strong>Geography matters.</strong> Music reigns nationwide, but Entertainment and Gaming see regional spikes.</li>
</ul>

<h2 id="behind-the-visualizations">Behind the Visualizations</h2>

<p>The analysis is powered by four main visualizations:</p>

<p><strong>1. Top 20 YouTube Channels (Bar Chart)</strong>:</p>

<p>To identify the most influential creators, I built a bar chart ranking the top 20 YouTube channels by total views. Since trending videos in the dataset appear repeatedly across multiple dates (as long as it remained trending), I used Tableau’s Level of Detail (LOD) calculation to extract the maximum value of views per unique video, avoiding duplicate entries. Then I aggregated these values to get the total views per channel.</p>

<p><strong>2. Likes vs. Dislikes Across YouTube Categories (Scatter Plot)</strong>:</p>

<p>The scatter plot reveals the relationship between likes and dislikes for trending videos in different categories. Each data point represents an individual video. The shape of each point corresponds to the video’s category, so users can immediately identify content types without relying on color alone.</p>

<p>Because the same video could appear on multiple trending days, I again applied an LOD calculation to capture only each video’s highest recorded engagement (likes and dislikes), instead of a cumulative total across multiple entries.</p>

<p>I also added a “Category Name” filter to let users focus on specific genres (like Comedy or Music) and investigate how sentiment patterns vary.</p>

<p><strong>3. Video and View Counts by Category (Dual-Axis Bar Chart)</strong>:</p>

<p>This chart addresses an important question: is volume or impact more important in content trends?</p>

<p>I created a dual-axis chart to show:</p>
<ul>
  <li>Bar chart: Total view counts per category (aggregated from highest view count per video)</li>
  <li>Dot plot: Number of unique trending videos in that category</li>
</ul>

<p>I also structured the hierarchy with “Channel Title” nested under “Category Name”, so users can drill down into specific creators within each genre.</p>

<p><strong>4. Top YouTube Categories by State (Interactive Map)</strong>:</p>

<p>The interactive map shows regional preferences with each state colored by its most popular YouTube category (based on total views). This visualization offers a regional perspective on video trends and helps understand geographic differences in content preferences.</p>

<p>Users can also apply the “Category Name” filter to see where specific content types are trending, even if they’re not the most dominant in that state. This interaction makes it easy to investigate niche audiences or regional differences in taste.</p>

<p><strong>Tooltips</strong></p>

<p>Every visualization includes tooltips that appear when users hover over data points. These tooltips provide additional context such as video titles, channel names, categories, view counts, likes, and dislikes, without cluttering the visual space. This design choice keeps the interface clean while giving users quick access to details for deeper insight.</p>

<h2 id="final-thoughts">Final Thoughts</h2>

<p>With Tableau, I turned a complex dataset into an accessible, interactive tool that surfaces insights through design and exploration. But this project was more than just building a dashboard. It was an exercise in turning raw data into narrative. Beyond the technical skills, this project pushed me to think like a storyteller, to guide users through the data, not just analyze it.</p>]]></content><author><name>Ngan Vu</name><email>&lt;mail@domain.tld&gt;</email></author><category term="youtube" /><category term="tableau dashboard" /><category term="tableau story" /><category term="data visualization" /><category term="storytelling" /><summary type="html"><![CDATA[An interactive Tableau dashboard that visualizes U.S. YouTube trending data to reveal viewer sentiment, top channels, and regional content preferences.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://nvu01.github.io//assets/img/posts/3/eyestetix-studio-Bm-5o5M2mAI-unsplash.jpg" /><media:content medium="image" url="https://nvu01.github.io//assets/img/posts/3/eyestetix-studio-Bm-5o5M2mAI-unsplash.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>